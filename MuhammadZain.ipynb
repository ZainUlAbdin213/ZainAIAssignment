{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "snrd7zhGz0j1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_openml(name='spambase', version=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHMJ2q3K0Kuj",
        "outputId": "be1550ba-5d2a-44d9-bd2c-80e6eb19c1cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data.data, data.target.astype(int)"
      ],
      "metadata": {
        "id": "LB-F5kDT0V0d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vhI8uLjU0nea"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train))\n",
        "lr_test_accuracy = accuracy_score(y_test, lr_model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afgveys-0ykm",
        "outputId": "18963338-c2c5-4534-e815-ec6ec5aa7fc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_train_accuracy = accuracy_score(y_train, svm_model.predict(X_train))\n",
        "svm_test_accuracy = accuracy_score(y_test, svm_model.predict(X_test))"
      ],
      "metadata": {
        "id": "4Z57L6yn02XE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train))\n",
        "rf_test_accuracy = accuracy_score(y_test, rf_model.predict(X_test))"
      ],
      "metadata": {
        "id": "xwZj_6rv07Td"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_train_accuracy = accuracy_score(y_train, nb_model.predict(X_train))\n",
        "nb_test_accuracy = accuracy_score(y_test, nb_model.predict(X_test))"
      ],
      "metadata": {
        "id": "OBdrF2En1Brf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'Logistic Regression': (lr_train_accuracy, lr_test_accuracy),\n",
        "    'SVM': (svm_train_accuracy, svm_test_accuracy),\n",
        "    'Random Forest': (rf_train_accuracy, rf_test_accuracy),\n",
        "    'Naive Bayes': (nb_train_accuracy, nb_test_accuracy)\n",
        "}"
      ],
      "metadata": {
        "id": "TgCxHkBK1DL9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for method, (train_acc, test_acc) in results.items():\n",
        "    print(f\"{method} - Training Accuracy: {train_acc:.4f}, Testing Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahWinyxM1HjJ",
        "outputId": "aae2628e-87b3-4467-b973-faf4d4f34508"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Training Accuracy: 0.9307, Testing Accuracy: 0.9197\n",
            "SVM - Training Accuracy: 0.7136, Testing Accuracy: 0.6623\n",
            "Random Forest - Training Accuracy: 0.9995, Testing Accuracy: 0.9544\n",
            "Naive Bayes - Training Accuracy: 0.8220, Testing Accuracy: 0.8208\n"
          ]
        }
      ]
    }
  ]
}